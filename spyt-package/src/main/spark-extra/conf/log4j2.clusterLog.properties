rootLogger.level=INFO
rootLogger.appenderRef.0.ref=console

appender.console.type=Console
appender.console.target=SYSTEM_ERR
appender.console.layout.type=PatternLayout
appender.console.layout.pattern=%d{yy/MM/dd HH:mm:ss} %p %c{1}: %m%n

# Set the default spark-shell log level to WARN. When running the spark-shell, the
# log level for this class is used to overwrite the root logger's log level, so that
# the user can have different defaults for the shell and regular Spark apps.
logger.repl.name=org.apache.spark.repl.Main
logger.repl.level=warn

# Settings to quiet third party logs that are too verbose
logger.jetty1.name=org.sparkproject.jetty
logger.jetty1.level=warn
logger.jetty2.name=org.sparkproject.jetty.util.component.AbstractLifeCycle
logger.jetty2.level=error
logger.repl_expr_typer.name=org.apache.spark.repl.SparkIMain$exprTyper
logger.repl_expr_typer.level=info
logger.repl_loop_interpreter.name=org.apache.spark.repl.SparkILoop$SparkILoopInterpreter
logger.repl_loop_interpreter.level=info
logger.parquet1.name=org.apache.parquet
logger.parquet1.level=error
logger.parquet2.name=parquet
logger.parquet2.level=error

# SPARK-9183: Settings to avoid annoying messages when looking up nonexistent UDFs in SparkSQL with Hive support
logger.RetryingHMSHandler.name=org.apache.hadoop.hive.metastore.RetryingHMSHandler
logger.RetryingHMSHandler.level=fatal
logger.FunctionRegistry.name=org.apache.hadoop.hive.ql.exec.FunctionRegistry
logger.FunctionRegistry.level=error

logger.spyt_launcher.name=tech.ytsaurus.spark.launcher
logger.spyt_launcher.level=debug

logger.spark.name=org.apache.spark
logger.spark.level=info
logger.spark.appenderRef.0.ref=console
