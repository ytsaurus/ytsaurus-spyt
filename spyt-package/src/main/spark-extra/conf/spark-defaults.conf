spark.ui.port                                         27001
spark.driver.port                                     27001
spark.blockManager.port                               27001
spark.port.maxRetries                                 200

spark.worker.cleanup.enabled                          true
spark.history.fs.cleaner.enabled                      true
spark.history.fs.createLogDirectory                   true
spark.history.fs.update.interval                      30s
spark.master.rest.enabled                             true
spark.master.rest.port                                27001
spark.master.ui.port                                  27001
spark.worker.ui.port                                  27001
spark.history.ui.port                                 27001

spark.master.metrics.registerStatic                   false
spark.worker.metrics.registerStatic                   false
spark.worker.metrics.sources                          org.apache.spark.deploy.yt.metrics.WorkerSource

spark.driver.memory                                   1G
spark.driver.maxResultSize                            1G
spark.executor.cores                                  1
spark.executor.memory                                 4G
spark.cores.max                                       20

spark.io.compression.codec                            snappy
spark.sql.extensions                                  tech.ytsaurus.spyt.format.YtSparkExtensions
spark.sql.sources.commitProtocolClass                 tech.ytsaurus.spyt.format.DelegatingOutputCommitProtocol
spark.sql.files.maxPartitionBytes                     2Gb
spark.yt.minPartitionBytes                            1Gb
spark.yt.write.batchSize                              2500000
spark.yt.read.keyColumnsFilterPushdown.enabled        true
spark.yt.read.keyPartitioningSortedTables.enabled     true
spark.yt.read.keyPartitioningSortedTables.unionLimit  1
spark.yt.read.ytPartitioning.enabled                  true
spark.yt.read.planOptimization.enabled                true

spark.datasource.yt.recursiveFileLookup               true

spark.sql.sources.parallelPartitionDiscovery.threshold 1024

spark.hadoop.fs.yt.impl                               tech.ytsaurus.spyt.fs.YtFileSystem
spark.hadoop.fs.ytCached.impl                         tech.ytsaurus.spyt.fs.YtCachedFileSystem
spark.hadoop.fs.ytEventLog.impl                       tech.ytsaurus.spyt.fs.eventlog.YtEventLogFileSystem
spark.hadoop.fs.ytEventLog.singleReadLimit            268435456
spark.hadoop.fs.ytTable.impl                          tech.ytsaurus.spyt.fs.YtTableFileSystem
spark.hadoop.fs.defaultFS                             ytTable:///
spark.hadoop.fs.null.impl                             tech.ytsaurus.spyt.fs.YtTableFileSystem
spark.hadoop.fs.AbstractFileSystem.yt.impl            tech.ytsaurus.spyt.fs.YtFs
spark.hadoop.yt.timeout                               30000
spark.hadoop.yt.dynTable.rowSize                      16777216

spark.yt.read.typeV3.enabled                          true
spark.yt.write.typeV3.enabled                         true
spark.hadoop.yt.write.typeV3.enabled                  true

spark.extraListeners                                  tech.ytsaurus.spyt.format.GlobalTransactionSparkListener
spark.yt.globalTransaction.enabled                    false
spark.yt.globalTransaction.timeout                    2m

spark.redaction.regex                                 (?i)secret|password|token

spark.eventLog.enabled                                false

spark.sql.autoBroadcastJoinThreshold                  -1

spark.hadoop.yt.read.arrow.enabled                    true

# TODO add to spark.driver.defaultJavaOptions:  --illegal-access=permit --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens java.base/java.lang=ALL-UNNAMED --add-opens java.base/java.util=ALL-UNNAMED --add-opens java.base/java.util.concurrent=ALL-UNNAMED --add-opens java.security.jgss/sun.security.krb5=ALL-UNNAMED
spark.driver.defaultJavaOptions                       -Dio.netty.tryReflectionSetAccessible=true
spark.executor.defaultJavaOptions                     -Dio.netty.tryReflectionSetAccessible=true

spark.sql.execution.arrow.pyspark.enabled             true
spark.sql.adaptive.enabled                            true

spark.sql.sources.useV1SourceList                     avro,csv,json,kafka,orc,parquet,text

spark.ui.showConsoleProgress                          false

spark.yt.schema.forcingNullableIfNoMetadata.enabled   false

spark.sql.cbo.enabled                                 true
spark.sql.cbo.joinReorder.enabled                     true

spark.sql.caseSensitive                               true

spark.executor.resource.gpu.amount                    0
